[run]
name = reward-0-more-fill-buffer
seed = 42
gpu_id = 1
logging_text_filename = 'log-batches.txt'

[env]
# Tokenizer is one of "sentencepiece" or "count"
tokenizer = "count"
num_problems_per_module : 10 ** 6
validation_percentage : 0.2
max_sequence_length : 375
vocab_size : 250
max_difficulty : 0
univariate_differentiation : True
num_environments = 50
tokenizer_filepath = "environment/tokenization/tokenizer.model"
max_formal_elements = 13
max_num_nodes = 10

data_dirpath = "mathematics_dataset-v1.0/train-easy"
selected_filenames = [
                     ;     'numbers__is_factor.txt',
                     ;     'numbers__is_prime.txt',
                     ;     'numbers__list_prime_factors.txt',
                     'calculus__differentiate.txt',
                     ;     'polynomials__evaluate.txt',
                     ;     'numbers__div_remainder.txt',
                     ;     'numbers__gcd.txt',
                     ;     'numbers__lcm.txt',
                     ;     'algebra__linear_1d.txt',
                     ;     'algebra__polynomial_roots.txt',
                     ;     'algebra__linear_2d.txt',
                     ;     'algebra__linear_1d_composed.txt',
                     ;     'algebra__linear_2d_composed.txt',
                     ;     'algebra__polynomial_roots_composed.txt',
                     ;     'calculus__differentiate_composed.txt',
                     ;     'numbers__div_remainder_composed.txt',
                     ;     'numbers__gcd_composed.txt',
                     ;     'numbers__is_factor_composed.txt',
                     ;     'numbers__is_prime_composed.txt',
                     ;     'numbers__lcm_composed.txt',
                     ;     'numbers__list_prime_factors_composed.txt',
                     ;     'polynomials__evaluate_composed.txt',
                     ;     'polynomials__compose.txt'
                     ]

# used only to initialize the tokenizer
types = [
        "Arbitrary",
        "Equation",
        "Function",
        "Expression",
        "Variable",
        "Value",
        "Rational"
        ]

operators = [
            "lookup_value",
            "solve_system",
            "append",
            "append_to_empty_list",
            "make_equation",
            "lookup_value_equation",
            "extract_isolated_variable",
            "substitution_left_to_right",
            "factor",
            "differentiate",
            "differentiate_wrt",
            "simplify",
            "make_function",
            "replace_arg",
            "mod",
            "gcd",
            "divides",
            "is_prime",
            "lcm",
            "lcd",
            "prime_factors",
            "evaluate_function",
            "not_op"
            ]

[model]
# network can be 'mlp' or 'transformer'
network = 'mlp'
nhead = 8
nhid = 512
nlayers = 2
model_filepath = None
# model_type can be 'value' or 'policy'
model_type = 'value'
action_embedding_size = 32
# Action Encoder
lstm_hidden_size = 128
lstm_nlayers = 1
weight_decay = 0

#If using an mlp model
[mlp]
n_hidden = 3
hidden_size = [256,256,128]

[train]
num_epochs = 100000000000000
replay_buffer_size = 50000
random_exploration_trajectory_cache_filepath = "mathematics_dataset-v1.0/default_0_trajectory_cache.sqlite"
model_exploration_trajectory_cache_filepath = "mathematics_dataset-v1.0/model_exploration_trajectory_cache.sqlite"

# fill buffer
buffer_threshold = 50
positive_to_negative_ratio = 1
fill_buffer_mode = 'balanced'
num_batches_until_fill_buffer = 100
batches_per_fill_buffer = 1

# training
batch_size = 128
lr = 0.001
max_grad_norm = 0.5
dropout = 0.2
epsilon = 0.2
gamma = 0.95
min_saved_steps_until_training = 10000
batches_per_epoch = 1

# LR scheduler
factor = 0.5
patience = 100000000000000000
min_lr = 0.00001
#max_lr = 0.01
#total_steps = 1000
#final_div_factor = 0.01

# replay priority
prioritization_exponent = 1
default_replay_buffer_priority = 1
batches_until_stop_replay_priority = 20000000000
n_batch_td_error = 1
sample_td_error_batch_size = 1024

# target network
use_target_network = False
batches_per_target_network_update = 500
batches_until_target_network = 20000

# eval
n_required_validation_episodes = 100
batches_per_eval = 100


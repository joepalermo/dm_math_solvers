[run]
name = differentiate_priority
seed = 42
gpu_id = 1

[env]
num_problems_per_module: 10 ** 6
validation_percentage: 0.2
max_sequence_length: 375
vocab_size: 250
max_difficulty: 0
univariate_differentiation: False
num_environments = 50
tokenizer_filepath = "environment/tokenization/tokenizer.model"
max_formal_elements = 13
max_num_nodes = 10
trajectory_cache_filepath = "mathematics_dataset-v1.0/trajectory_cache.sqlite"

data_dirpath = "mathematics_dataset-v1.0/train-easy"
selected_filenames = [
;     'numbers__is_factor.txt',
;     'numbers__is_prime.txt',
;     'numbers__list_prime_factors.txt',
     'calculus__differentiate.txt',
;     'polynomials__evaluate.txt',
;     'numbers__div_remainder.txt',
;     'numbers__gcd.txt',
;     'numbers__lcm.txt',
;     'algebra__linear_1d.txt',
;     'algebra__polynomial_roots.txt',
;     'algebra__linear_2d.txt',
;     'algebra__linear_1d_composed.txt',
;     'algebra__linear_2d_composed.txt',
;     'algebra__polynomial_roots_composed.txt',
;     'calculus__differentiate_composed.txt',
;     'numbers__div_remainder_composed.txt',
;     'numbers__gcd_composed.txt',
;     'numbers__is_factor_composed.txt',
;     'numbers__is_prime_composed.txt',
;     'numbers__lcm_composed.txt',
;     'numbers__list_prime_factors_composed.txt',
;     'polynomials__evaluate_composed.txt',
;     'polynomials__compose.txt'
                     ]

# used only to initialize the tokenizer
types = [
         "Arbitrary",
         "Equation",
         "Function",
         "Expression",
         "Variable",
         "Value",
         "Rational"
         ]

operators = [
    "lookup_value",
    "solve_system",
    "append",
    "append_to_empty_list",
    "make_equation",
    "lookup_value_equation",
    "extract_isolated_variable",
    "substitution_left_to_right",
    "factor",
    "differentiate",
    "differentiate_wrt",
    "simplify",
    "make_function",
    "replace_arg",
    "mod",
    "gcd",
    "divides",
    "is_prime",
    "lcm",
    "lcd",
    "prime_factors",
    "evaluate_function",
    "not_op"
    ]

[model]
nhead = 8
nhid = 512
nlayers = 1
model_filepath = None
# model_type can be 'value' or 'policy'
model_type = 'value'

[train]
batch_size = 64
buffer_threshold = 32
positive_to_negative_ratio = 1
lr = 0.001
dropout = 0.1
n_required_validation_episodes = 100
max_grad_norm = 0.5
#DQN:
epsilon = 1
gamma = 0.9
# mode can be 'positive_only' or 'balanced'
mode = 'balanced'
num_buffers = 10000
fill_buffer_max_steps = 1000
min_saved_trajectories_until_training = 1000
batches_per_eval = 50
batches_per_train = 5
# scheduler
factor = 0.2
patience = 15
min_lr = 0.01
prioritization_exponent = 5
# Priority
default_replay_buffer_priority = 100